{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nbH8DiPfnFo"
   },
   "source": [
    "# Image Classification - The Multi-class Weather Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_eFY2j9fnFw"
   },
   "source": [
    "\n",
    "##  Data exploration, preparation, and partition\n",
    "\n",
    "###  data partition \n",
    "\n",
    "I will generate three CSV files named `my_training.csv`, `my_validation.csv`, and `my_test.csv` that partition the dataset into the training, validation, and test set. Each CSV file contains the following two fields:\n",
    "\n",
    "- File path\n",
    "- Image label\n",
    "\n",
    "For example, the file `my_training.csv` could start like this:\n",
    "\n",
    "```csv\n",
    "dataset2/cloudy1.jpg,cloudy\n",
    "dataset2/shine170.jpg,shine\n",
    "dataset2/shine116.jpg,shine\n",
    "```\n",
    "\n",
    "I will Make sure that the partitions are created randomly, so that the label distribution is similar in each partition. Also, make sure that the samples are sorted in no particular order (randomly)\n",
    "\n",
    "Then I'll display the label distribution of each partition, and display the first 10 rows of each partition.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_partition_csv(dataset_dir, label_names, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_seed=42):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    label_pattern = re.compile(r'^([a-zA-Z]+)')\n",
    "    #iterating over all files in the dataset directory\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.endswith(\".jpg\"):\n",
    "            file_paths.append(os.path.join(dataset_dir, file))\n",
    "            #extracting label from the filename using regular expressions\n",
    "            match = label_pattern.match(file)\n",
    "            if match:\n",
    "                label = match.group(1)\n",
    "                labels.append(label)\n",
    "    #creating a DataFrame with file paths and corresponding labels\n",
    "    df = pd.DataFrame({'File_Path': file_paths, 'Label': labels})\n",
    "    #shuffling the DataFrame\n",
    "    df = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "    #calculating the number of samples for each partition\n",
    "    num_samples = len(df)\n",
    "    num_train = int(train_ratio * num_samples)\n",
    "    num_val = int(val_ratio * num_samples)\n",
    "    #spliting the DataFrame into train, validation, and test sets\n",
    "    train_df = df.iloc[:num_train]\n",
    "    val_df = df.iloc[num_train:num_train+num_val]\n",
    "    test_df = df.iloc[num_train+num_val:]\n",
    "    #saving the partition information to CSV files\n",
    "    train_df.to_csv(os.path.join( 'my_training.csv'), index=False)\n",
    "    val_df.to_csv(os.path.join( 'my_validation.csv'), index=False)\n",
    "    test_df.to_csv(os.path.join('my_test.csv'), index=False)\n",
    "    partitions = {'Training': train_df, 'Validation': val_df, 'Test': test_df}\n",
    "    for partition_name, partition_df in partitions.items():\n",
    "        print(f\"{partition_name} Partition:\")\n",
    "        print(\"Label Distribution:\")\n",
    "        print(partition_df['Label'].value_counts())\n",
    "        print(\"\\nFirst 10 Rows:\")\n",
    "        print(partition_df.head(10))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['cloudy', 'rain', 'shine', 'sunrise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Partition:\n",
      "Label Distribution:\n",
      "Label\n",
      "sunrise    235\n",
      "cloudy     216\n",
      "shine      181\n",
      "rain       153\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 Rows:\n",
      "                 File_Path    Label\n",
      "0  dataset2\\sunrise283.jpg  sunrise\n",
      "1  dataset2\\sunrise150.jpg  sunrise\n",
      "2   dataset2\\cloudy186.jpg   cloudy\n",
      "3     dataset2\\shine54.jpg    shine\n",
      "4   dataset2\\sunrise45.jpg  sunrise\n",
      "5  dataset2\\sunrise151.jpg  sunrise\n",
      "6     dataset2\\rain172.jpg     rain\n",
      "7   dataset2\\sunrise66.jpg  sunrise\n",
      "8    dataset2\\cloudy24.jpg   cloudy\n",
      "9    dataset2\\shine204.jpg    shine\n",
      "\n",
      "\n",
      "Validation Partition:\n",
      "Label Distribution:\n",
      "Label\n",
      "sunrise    69\n",
      "cloudy     44\n",
      "shine      28\n",
      "rain       27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 Rows:\n",
      "                   File_Path    Label\n",
      "785  dataset2\\sunrise176.jpg  sunrise\n",
      "786       dataset2\\rain7.jpg     rain\n",
      "787    dataset2\\cloudy84.jpg   cloudy\n",
      "788  dataset2\\sunrise210.jpg  sunrise\n",
      "789  dataset2\\sunrise141.jpg  sunrise\n",
      "790    dataset2\\cloudy31.jpg   cloudy\n",
      "791   dataset2\\cloudy122.jpg   cloudy\n",
      "792  dataset2\\sunrise279.jpg  sunrise\n",
      "793   dataset2\\sunrise56.jpg  sunrise\n",
      "794      dataset2\\rain30.jpg     rain\n",
      "\n",
      "\n",
      "Test Partition:\n",
      "Label Distribution:\n",
      "Label\n",
      "sunrise    52\n",
      "shine      44\n",
      "cloudy     40\n",
      "rain       33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 Rows:\n",
      "                  File_Path    Label\n",
      "953   dataset2\\shine246.jpg    shine\n",
      "954    dataset2\\rain114.jpg     rain\n",
      "955   dataset2\\shine220.jpg    shine\n",
      "956    dataset2\\rain199.jpg     rain\n",
      "957  dataset2\\sunrise43.jpg  sunrise\n",
      "958    dataset2\\shine48.jpg    shine\n",
      "959    dataset2\\rain151.jpg     rain\n",
      "960   dataset2\\cloudy61.jpg   cloudy\n",
      "961     dataset2\\shine8.jpg    shine\n",
      "962   dataset2\\shine201.jpg    shine\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"dataset2\"\n",
    "create_partition_csv(dataset_dir, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T04RQSn6fnF2"
   },
   "source": [
    "###  preprocessing and preparation \n",
    "\n",
    "Use TensorFlow's `TextLineDataset` to generate datasets for training, validation, and test. The datasets need to produce images that are re-sized to dimensions 230 x 230 and 3 channels, and the values of the pixels must be normalised to the range [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amirs\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "import tensorflow_hub as hub\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "0p0bHC1zfnF3"
   },
   "outputs": [],
   "source": [
    "#we redefine read_and decode so that it uses TensorFlow's tensors\n",
    "label_names = ['cloudy', 'rain', 'shine', 'sunrise']\n",
    "def read_and_decode(filename, reshape_dims):\n",
    "\n",
    "  #reading the file\n",
    "  img = tf.io.read_file(filename)\n",
    "\n",
    "  #converting the compressed string to a 3D uint8 tensor.\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "\n",
    "  #using convert_image_dtype to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "  #resizing the image to the desired size.\n",
    "  return tf.image.resize(img, reshape_dims)\n",
    "\n",
    "#decode_csv changed so that the label is the inden into CLASS_NAMES array\n",
    "def decode_csv(csv_row):\n",
    "\n",
    "  record_defaults = [\"path\", \"label\"]\n",
    "  filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "  img = read_and_decode(filename, [230, 230])\n",
    "  label = tf.math.equal(label_names, label_string) \n",
    "\n",
    "  return img, label\n",
    "\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.TextLineDataset(\"training.csv\").map(decode_csv).batch(32)\n",
    ")\n",
    "\n",
    "val_dataset = (\n",
    "    tf.data.TextLineDataset(\"validation.csv\").map(decode_csv).batch(32)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.TextLineDataset(\"test.csv\").map(decode_csv).batch(32)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(32, 230, 230, 3)\n",
      "(13, 230, 230, 3)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dataset.take(25):\n",
    "    print(images.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJMFW8x2fnF5"
   },
   "source": [
    "##  A simple classifier\n",
    "\n",
    "### First classifier \n",
    "\n",
    "Create a simple model that contains the following layers:\n",
    "\n",
    "- A `Flatten` layer.\n",
    "- The output layer with the correct size and activation function for this classification task.\n",
    "\n",
    "Then, train the model with the training data. Use the validation data to determine when to stop training. Finally, test the trained model on the test data and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "BV93NDzefnF5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158700</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,313,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158700\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m20,313,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,314,244</span> (77.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,314,244\u001b[0m (77.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,314,244</span> (77.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,314,244\u001b[0m (77.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.3432 - loss: 81.9981 - val_accuracy: 0.6347 - val_loss: 1.4969\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.6883 - loss: 1.9512 - val_accuracy: 0.7066 - val_loss: 1.3339\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.7281 - loss: 1.3414 - val_accuracy: 0.6886 - val_loss: 1.3242\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.7555 - loss: 0.9365 - val_accuracy: 0.7365 - val_loss: 0.7133\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.7212 - loss: 1.1110 - val_accuracy: 0.7246 - val_loss: 1.0256\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.7240 - loss: 1.3593 - val_accuracy: 0.7126 - val_loss: 1.0776\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.7075 - loss: 1.2172 - val_accuracy: 0.6108 - val_loss: 1.4806\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.7322 - loss: 1.0569 - val_accuracy: 0.7485 - val_loss: 0.9059\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.7482 - loss: 1.0572 - val_accuracy: 0.6886 - val_loss: 2.0085\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.7849 - loss: 1.0413 - val_accuracy: 0.6946 - val_loss: 1.6192\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(230, 230, 3)))#flatten layer\n",
    "model.add(layers.Dense(128, activation='relu'))#dense layer with ReLU activation\n",
    "model.add(layers.Dense(4, activation='softmax'))#output layer with softmax activation for 4 classes\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "in the cell below i wrote the code that displays the accuracy of the model on the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6819 - loss: 1.4461\n",
      "Test Accuracy: 0.7041420340538025\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the accuracy of the model is : 0.7041420340538025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7x5pFFXfnF6"
   },
   "source": [
    "### A more complex classifier\n",
    "Try a more complex architecture that has 1 or more hidden layers with dropout. For this more complex architecture, use `keras-tuner` and run it with a reasonable choice of possible parameters. You may try among the following:\n",
    "\n",
    "- Number of hidden layers\n",
    "- Sizes of hidden layers\n",
    "- Dropout rate\n",
    "- Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 40s]\n",
      "val_accuracy: 0.7544910311698914\n",
      "\n",
      "Best val_accuracy So Far: 0.772455096244812\n",
      "Total elapsed time: 00h 04m 49s\n",
      "{'lrate': 0.0016772511235787196, 'num_hidden_layers': 1, 'units_0': 384, 'dropout_0': 0.2, 'units_1': 32, 'dropout_1': 0.0, 'units_2': 32, 'dropout_2': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amirs\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158700</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">60,941,184</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,540</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158700\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │    \u001b[38;5;34m60,941,184\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,540\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,942,724</span> (232.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,942,724\u001b[0m (232.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,942,724</span> (232.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,942,724\u001b[0m (232.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#defining the parameters (you can adjust these as needed)\n",
    "def build_model(hp):\n",
    "    lrate = hp.Float('lrate', 1e-4, 1e-1, sampling='log')\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(230, 230, 3)))  #flatten layer\n",
    "    #number of hidden layers\n",
    "    num_hidden_layers = hp.Int('num_hidden_layers', min_value=1, max_value=3, default=1)\n",
    "    for i in range(num_hidden_layers):\n",
    "        units = hp.Int(f'units_{i}', min_value=32, max_value=512, step=32)\n",
    "        dropout_rate = hp.Float(f'dropout_{i}', min_value=0.0, max_value=0.9, step=0.1)\n",
    "        model.add(keras.layers.Dense(units=units, activation='relu'))\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "    #output layer\n",
    "    model.add(keras.layers.Dense(4, activation='softmax'))  #output layer with softmax activation for 4 classes\n",
    "    #compile the model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lrate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "#initialize the tuner\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=kt.Objective('val_accuracy', 'max'),\n",
    "    max_trials=10,\n",
    "    num_initial_points=2,\n",
    "    overwrite=True  #true to start afresh\n",
    ")\n",
    "#search for the best hyperparameters\n",
    "tuner.search(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=5,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=1)]\n",
    ")\n",
    "#get the best hyperparameters and model summary\n",
    "topN = 1\n",
    "for x in range(topN):\n",
    "    print(tuner.get_best_hyperparameters(topN)[x].values)\n",
    "    print(tuner.get_best_models(topN)[x].summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158700</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">60,941,184</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,540</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158700\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │    \u001b[38;5;34m60,941,184\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,540\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,942,724</span> (232.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,942,724\u001b[0m (232.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,942,724</span> (232.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,942,724\u001b[0m (232.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - accuracy: 0.3242 - loss: 170.0759 - val_accuracy: 0.5928 - val_loss: 17.3159\n",
      "Epoch 2/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - accuracy: 0.6431 - loss: 29.2969 - val_accuracy: 0.7545 - val_loss: 4.3645\n",
      "Epoch 3/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.6946 - loss: 5.2566 - val_accuracy: 0.7665 - val_loss: 1.0583\n",
      "Epoch 4/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - accuracy: 0.7129 - loss: 0.7957 - val_accuracy: 0.7545 - val_loss: 0.8654\n",
      "Epoch 5/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - accuracy: 0.7540 - loss: 0.6760 - val_accuracy: 0.7126 - val_loss: 0.8668\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.Sequential()\n",
    "best_model.add(keras.layers.Flatten(input_shape=(230, 230, 3)))\n",
    "best_model.add(keras.layers.Dense(units=384, activation='relu'))\n",
    "best_model.add(keras.layers.Dropout(0.2))\n",
    "best_model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "best_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0016772511235787196),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "best_model.summary()\n",
    "history = best_model.fit(train_dataset, validation_data=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neYN1eiIfnF8"
   },
   "source": [
    "Write text below where you explain and justify your decision choices made in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71dBL-k0fnF8"
   },
   "source": [
    "#### Justification\n",
    "in this task i was required to write use keras tuner to create a complex model with one or more hidden layers so i used a for loop to test different number of layers between 1 to 3 and find the best, for the number of nodes or neurons in each layer i wanted to test a number between 32 and 512 with a step size of 32 so it does test the different sizes of layers to train the model, for the drop out rate i wanted to be between 0 and 0.9 since the dropout rate of 1 would be dropping the whole nodes of layer which is not ideal, learning rate's min and max value is taken from the lecture slides which can be a common range to use for this purpose. Lastly i wanted the keras tuner to be searching through this range of different hyper parameters and pinpoint the optimal values for them to achieve the highest accuracy. i set the number of epochs in this task to 5 because it would've taken much more computing power and time to use higher number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsM7wXbIfnF9"
   },
   "source": [
    "### 2.3 Error analysis (1 mark)\n",
    "\n",
    "Evaluate your best-performing system from task 2 against the system of task 1 and answer the following questions.\n",
    "\n",
    "1. Which system had a better accuracy on the test data?\n",
    "2. Which system had a lower degree of overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6819 - loss: 1.4461\n",
      "Test Accuracy of Simple Classifier: 0.7041420340538025\n"
     ]
    }
   ],
   "source": [
    "test_loss_simple, test_accuracy_simple = model.evaluate(test_dataset)\n",
    "print('Test Accuracy of Simple Classifier:', test_accuracy_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of the first model on test data: 0.7041420340538025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7165 - loss: 0.6515\n",
      "Test Accuracy: 0.7396449446678162\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(test_dataset)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy of the second model on test data: 0.7396449446678162"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best-performing model is the model trained for task 2.2 A more complex classifier, since i utilized keras-tuner to find out the optimal hyperparameters for the model. \n",
    "Which system had a better accuracy on the test data? the second model has a better accuracy on the test data\n",
    "Which system had a lower degree of overfitting? based on my analysis of the models the second model has a lower degree of overfitting since the difference between the accuracy of the model on the validation data and the test data is less than the first model trained.\n",
    "\n",
    "##### First model\n",
    "best accuracy on validation data:  0.7849\n",
    "\n",
    "accuracy on test data: 0.7041\n",
    "\n",
    "this model is indicating a higher degree of overfitting since the accuracy drops significantly on test data\n",
    "\n",
    "##### second model\n",
    "best accuracy on validation data: 0.7724\n",
    "\n",
    "accuracy on test data: 0.7396\n",
    "\n",
    "this model showcases a lower degree of overfitting because the accuracy of the model changes less than the first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJgTJjhUfnF9"
   },
   "source": [
    "##  A more complex classifier  \n",
    "\n",
    "### Using ConvNets \n",
    "\n",
    "I'll implement a model that uses a sequence of at least two `ConvD`, each one followed with `MaxPooling2D`. Use reasonable numbers for the hyperparameters (number of filters, kernel size, pool size, activation, etc), base on what we have seen in the lectures. Feel free to research the internet and / or generative AI to help you find a reasonable choice of hyperparameters. For this task, do not use pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "tvZQQPSJfnF-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amirs\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">228</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">228</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200704</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">802,820</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m228\u001b[0m, \u001b[38;5;34m228\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200704\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │       \u001b[38;5;34m802,820\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">822,212</span> (3.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m822,212\u001b[0m (3.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">822,212</span> (3.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m822,212\u001b[0m (3.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#defining the model\n",
    "ConvNets_model = models.Sequential()\n",
    "#convolutional layers\n",
    "ConvNets_model.add(layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(230, 230, 3)))\n",
    "ConvNets_model.add(layers.MaxPooling2D(pool_size=2))\n",
    "ConvNets_model.add(layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\"))\n",
    "ConvNets_model.add(layers.MaxPooling2D(pool_size=2))\n",
    "#flatten the output for Dense layers\n",
    "ConvNets_model.add(layers.Flatten())\n",
    "ConvNets_model.add(layers.Dense(4, activation=\"softmax\"))  \n",
    "#compiling the model\n",
    "ConvNets_model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.00001),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "ConvNets_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 305ms/step - accuracy: 0.3704 - loss: 1.3313 - val_accuracy: 0.5988 - val_loss: 1.0085\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - accuracy: 0.6695 - loss: 1.1232 - val_accuracy: 0.7066 - val_loss: 0.8672\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 290ms/step - accuracy: 0.7556 - loss: 0.9621 - val_accuracy: 0.8024 - val_loss: 0.7604\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - accuracy: 0.8104 - loss: 0.8483 - val_accuracy: 0.8084 - val_loss: 0.6834\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 354ms/step - accuracy: 0.8248 - loss: 0.7606 - val_accuracy: 0.8204 - val_loss: 0.6243\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - accuracy: 0.8302 - loss: 0.6908 - val_accuracy: 0.8144 - val_loss: 0.5772\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.8320 - loss: 0.6340 - val_accuracy: 0.8144 - val_loss: 0.5392\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.8381 - loss: 0.5882 - val_accuracy: 0.8204 - val_loss: 0.5086\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.8379 - loss: 0.5510 - val_accuracy: 0.8323 - val_loss: 0.4844\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.8418 - loss: 0.5211 - val_accuracy: 0.8263 - val_loss: 0.4652\n"
     ]
    }
   ],
   "source": [
    "history = ConvNets_model.fit(train_dataset, validation_data=val_dataset,epochs=10,callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8124 - loss: 0.5004\n",
      "Test Accuracy: 0.8284023404121399\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = ConvNets_model.evaluate(test_dataset)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the ConvNets model on test data is: 0.8284023404121399"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "152E3mgdfnF_"
   },
   "source": [
    "### Using pre-trained models\n",
    "\n",
    "Use MobileNet, pre-trained on imagenet as discussed in the lectures. Add the correct classification layer, and train it with your data. Make sure that you freeze MobileNet's weights during training. Also, make sure you use a reasonable schedule for the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "FOeToHlyfnF_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amirs\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"weather_classification\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"weather_classification\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ weather_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_hidden (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m20,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ weather_prob (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m68\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,564</span> (80.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,564\u001b[0m (80.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,564</span> (80.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,564\u001b[0m (80.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 189ms/step - accuracy: 0.4004 - loss: 1.3790 - val_accuracy: 0.7425 - val_loss: 0.5226\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 0.8236 - loss: 0.4845 - val_accuracy: 0.9222 - val_loss: 0.2470\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 0.9230 - loss: 0.2400 - val_accuracy: 0.9401 - val_loss: 0.1762\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 0.9499 - loss: 0.1617 - val_accuracy: 0.9461 - val_loss: 0.1515\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 0.9570 - loss: 0.1278 - val_accuracy: 0.9461 - val_loss: 0.1385\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 0.9665 - loss: 0.1068 - val_accuracy: 0.9581 - val_loss: 0.1279\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - accuracy: 0.9699 - loss: 0.0909 - val_accuracy: 0.9581 - val_loss: 0.1185\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 0.9713 - loss: 0.0780 - val_accuracy: 0.9581 - val_loss: 0.1103\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 0.9776 - loss: 0.0668 - val_accuracy: 0.9581 - val_loss: 0.1052\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 0.9837 - loss: 0.0576 - val_accuracy: 0.9521 - val_loss: 0.1037\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "\n",
    "#loading compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "\n",
    "#defining a function to create the model\n",
    "def create_model():\n",
    "    premodel = tf.keras.Sequential(name='weather_classification')\n",
    "    premodel.add(tf.keras.layers.InputLayer(input_shape=(224, 224, 3)))  #adjusted input shape for MobileNet model\n",
    "    premodel.add(tf.keras.layers.Lambda(lambda x: tf.image.resize(x, (224, 224))))  # Resize images\n",
    "    premodel.add(tf.keras.layers.Lambda(lambda x: hub.KerasLayer(\n",
    "        \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
    "        trainable=False)(x))) #to freeze MobileNet's weights during training\n",
    "    premodel.add(tf.keras.layers.Dense(16, activation='relu', name='dense_hidden'))\n",
    "    premodel.add(tf.keras.layers.Dense(4, activation='softmax', name='weather_prob'))\n",
    "    return premodel\n",
    "\n",
    "#function to train and evaluate the model\n",
    "def train_and_evaluate(batch_size=32, lrate=0.001, num_hidden=16, epochs=10):\n",
    "    train_dataset = (tf.data.TextLineDataset(\"training.csv\")\n",
    "                     .map(decode_csv)\n",
    "                     .batch(batch_size))\n",
    "    eval_dataset = (tf.data.TextLineDataset(\"validation.csv\")\n",
    "                    .map(decode_csv)\n",
    "                    .batch(batch_size))\n",
    "\n",
    "    premodel = create_model()\n",
    "    premodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print(premodel.summary())\n",
    "    history = premodel.fit(train_dataset, validation_data=val_dataset, epochs=epochs,\n",
    "                        callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)])\n",
    "    return premodel\n",
    "\n",
    "premodel = train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9655 - loss: 0.0976\n",
      "Test Accuracy of Simple Classifier: 0.9704142212867737\n"
     ]
    }
   ],
   "source": [
    "test_loss_simple, test_accuracy_simple = premodel.evaluate(test_dataset)\n",
    "print('Test Accuracy of Simple Classifier:', test_accuracy_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the ore-trained ConvNets model on test data is: 0.9704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sb0NTIk1fnGA"
   },
   "source": [
    "### Comparative evaluation \n",
    "\n",
    "Here I Compare the evaluation results of the best systems from tasks previous models and answer the following questions.\n",
    "\n",
    "1. What system perform best on the test set?\n",
    "2. Report the accuracy of your best system on each of the different weather categories. What type of weather was most difficult to detect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "according to the model performance reports above this section the highest accuracy on test data is indicated when evaluating the pre-trained CNN model, it has a accuracy of 0.9704 on the test set while the other three have an accuracy of:\n",
    "\n",
    "Accuracy of the first simple classifier model on test data: 0.7041\n",
    "\n",
    "Accuracy of the more complex classifier model on test data: 0.7396\n",
    "\n",
    "Accuracy of the ConvNets model on test data is:  0.8284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = [0.7041, 0.7396, 0.8284, 0.9704]\n",
    "labels = ['simple classifier', 'complex classifier', 'ConvNets', 'pre-trained CNN']\n",
    "plt.bar(labels, values, color='skyblue')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Comparison of accuracies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "Xm9mYpAzfnGA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9655 - loss: 0.0976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Accuracy for cloudy: 0.9215686274509803\n",
      "Accuracy for rain: 1.0\n",
      "Accuracy for shine: 0.9714285714285714\n",
      "Accuracy for sunrise: 1.0\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model on the test dataset\n",
    "test_loss, test_accuracy = premodel.evaluate(test_dataset)\n",
    "\n",
    "#initializing dictionary to store counts and accuracies for each label\n",
    "label_accuracies = {label: [] for label in label_names}\n",
    "\n",
    "#iterating through the test dataset and calculate accuracy for each label\n",
    "for images, labels in test_dataset:\n",
    "    predictions = premodel.predict(images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(labels, axis=1)\n",
    "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "        label_name = label_names[true_label]\n",
    "        is_correct = true_label == predicted_label\n",
    "        label_accuracies[label_name].append(is_correct)\n",
    "\n",
    "#calculating and print accuracy for each label\n",
    "for label, accuracies in label_accuracies.items():\n",
    "    accuracy = np.mean(accuracies)\n",
    "    print(f\"Accuracy for {label}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### most difficult to detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z1D7X0vfnGB"
   },
   "source": [
    "The most difficult weather category to detect is cloudy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
